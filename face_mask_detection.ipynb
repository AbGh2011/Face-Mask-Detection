{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc156e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abolfazl\\Desktop\\projects\\Face-Mask-Detection\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import cv2\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb7fd4",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b402a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/andrewmvd/face-mask-detection?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398M/398M [03:58<00:00, 1.75MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Abolfazl\\.cache\\kagglehub\\datasets\\andrewmvd\\face-mask-detection\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# دانلود دیتاست\n",
    "path = kagglehub.dataset_download(\"andrewmvd/face-mask-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141d24f",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# جدا کردن تصاویر، اسم تصاویر، لیبل ها و باوندینگ باکس ها توی لیست های جدا\n",
    "\n",
    "# مسیر دیتاست\n",
    "images_path = os.path.join(path, 'images') # مسیر تصاویر\n",
    "annotations_path = os.path.join(path, 'annotations') # مسیر انوتیشن‌ ها\n",
    "\n",
    "# لیست تصاویر و آماده‌سازی داده‌ ها\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir(images_path):\n",
    "    img_path = os.path.join(images_path, filename) # مسیر تصویر\n",
    "    img = cv2.imread(img_path) # خوندن تصویر\n",
    "\n",
    "    # استخراج لیبل و باوندینگ باکس ها از انوتیشنِ تصویر\n",
    "    xml_file = os.path.join(annotations_path, filename.replace('.png', '.xml'))\n",
    "    tree = ET.parse(xml_file) # تبدیل انوتیشن به فرمت شی قابل فهم و ساده به صورت درختی\n",
    "    root = tree.getroot() # ( <annotation>...</annotation> ) ریشه درخت \n",
    "\n",
    "    for object in root.findall('object'): # پیدا کردن همه آبجکت های توی ریشه. هر آبجکت یه فرد توی تصویره\n",
    "        class_name = object.find('name').text # کلاس فرد (با ماسک | بدون ماسک | با ماسک نادرست زده شده) بدون تگ\n",
    "        bounding_box = object.find('bndbox') # باوندینگ باکس فرد\n",
    "        \n",
    "        # مختصات باوندینگ باکس\n",
    "        x_start = int(bounding_box.find('xmin').text)\n",
    "        y_start = int(bounding_box.find('ymin').text)\n",
    "        x_end = int(bounding_box.find('xmax').text)\n",
    "        y_end = int(bounding_box.find('ymax').text)\n",
    "\n",
    "        faces.append(cv2.resize(img[y_start:y_end, x_start:x_end], (216, 216))) # اضافه کردن تصویر کراپ شده باوندینگ باکس به لیست چهره ها\n",
    "    \n",
    "        # بررسی تعلق به هر کلاس\n",
    "        if class_name == 'without_mask':\n",
    "            labels.append([0])\n",
    "        elif class_name == 'with_mask':\n",
    "            labels.append([1])\n",
    "        elif class_name == 'mask_weared_incorrect':\n",
    "            labels.append([2])\n",
    "\n",
    "\n",
    "# تبدیل لیست ها به آرایه نامپای برای پردازش توسط مدل\n",
    "faces = np.array(faces)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# نرمالایز کردن تصاویر\n",
    "faces = faces.astype('float32') / 255.0\n",
    "\n",
    "# (80%)تقسیم به داده های ترِین(20%) و تست\n",
    "train_faces, test_faces, train_labels, test_labels = train_test_split(\n",
    "    faces, labels, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "# برای محاسبه بهتر تابع هزینه توسط مدل One-Hot Endcoding تبدیل لیبل ها به\n",
    "train_labels_onehot = tf.keras.utils.to_categorical(train_labels, num_classes=3)\n",
    "test_labels_onehot = tf.keras.utils.to_categorical(test_labels, num_classes=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
